\documentclass{beamer}
\usetheme{Frankfurt}
\usecolortheme{rose}
\usepackage{CJKutf8}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{float}
\usepackage{graphicx} 
\usepackage{diagbox}
\usepackage{tikz}
\usetikzlibrary{trees}  
\usepackage{indentfirst}
\usepackage{float}
 
\begin{document}
\begin{CJK}{UTF8}{gkai} 

\title{Capturing the Intangible Concept of Information In Hydrological Simulation\\\raisebox{0.5mm}{------}Perspectives From Shannon and Kolmogorov}
\author{Pan Baoxiang \  \ Cong Zhentao}
\institute{Institute of Hydrology and Water Resources \\Tsinghua University}
\date{\today}
\maketitle
\begin{frame}
\frametitle{Outline}
\begin{itemize}
\item Introduction
\item Shannon Information \& Kolmogorov Complexity
\item Case Study 
\item Discussion \& Conclusion
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Introduction}
\onslide<1->{
Questions:
\begin{itemize}
\item Given the p.d.f. of the rainfall amount of a certain year, through how many guesses could we reach its interval estimation to a fixed accuracy?
\item Give an efficient description of an annual rainfall series.  
\end{itemize}}

 

\onslide<2->{\center{Information is Bits $+$ Context.}}
\end{frame}

\begin{frame}
\frametitle{Measuring Information Contents}
 
\begin{tabular}{c p{4.4cm}  p{4.3cm} }
\toprule
&\multicolumn{1}{c}{Shannon Entropy}&\multicolumn{1}{c}{Kolmogorov Complexity} \\ \hline
Definition & 
$H(X)=-\Sigma p(x)logp(x)$ & The length (in bits) of the shortest computer program \\ 
&$h(X)=-\int f(x)logf(x)dx$&that prints the sequence and then halts.\\ 
\\
Focus&\multicolumn{1}{c}{Random Source}&\multicolumn{1}{c}{Object}\\
&\multicolumn{1}{c}{Object irrelevant}&\multicolumn{1}{c}{Probability irrelevant}\\
\\
Property&$H(X,Y)\leq H(X)+H(Y)$&\multicolumn{1}{c}{Uncomputability}\\
\\
Estimator&\multicolumn{1}{c}{p.d.f Estimator}&\multicolumn{1}{c}{Compressor}\\
\\
Dimension&\multicolumn{2}{c}{Bit}\\
\hline
\end{tabular}
 

\end{frame}

\begin{frame}
\frametitle{Measuring Information Connections}
\begin{tabular}{c p{4.5cm}  p{4.2cm} }
\toprule
&\multicolumn{1}{c}{Mutual Information(S)}&\multicolumn{1}{c}{Mutual Information(K)} \\ \hline
Definition & 
\scriptsize{$I(X;Y)=\sum p(x,y)log\frac{p(x,y)}{p(x)p(y)}$} & \scriptsize{$KC(X)+KC(Y)-KC(X,Y)$} \\ 
&\scriptsize{$I(X;Y)=\int f(x,y)log\frac{f(x,y)}{f(x)f(y)}dxdy$} \\ 
\\
Focus&\multicolumn{1}{c}{Random Source}&\multicolumn{1}{c}{Object}\\
&\multicolumn{1}{c}{Object irrelevant}&\multicolumn{1}{c}{Probability irrelevant}\\
\\
Property&\multicolumn{1}{c}{Symmetry}&\multicolumn{1}{c}{Uncomputability}\\
\\
Estimator&\multicolumn{1}{c}{KNN+SVR}&\ \scriptsize{$ZIP(X)+ZIP(Y)-ZIP(X,Y)$} \\
\\
Dimension&\multicolumn{2}{c}{Bit}\\
\hline
\end{tabular} 
\end{frame}

\begin{frame}
\frametitle{Bits in Hydrological Simulation Context}
 $$ Hydrological \ Simulation \left\{
\begin{aligned}
 &observation \left\{\begin{aligned}
&Input \ Measurements \ X_i\\
&Output \ Measurements \ X_o\\
\end{aligned}\right.\\
\\
 &Model \ \ \left\{\begin{aligned}
&Output\ Simulation \ X_s\\
&State\ Variable \ Simulation \ S \\
&Parameters \\
&Model Structure \\
\end{aligned}\right.\\
\end{aligned}
\right.
$$ 
\end{frame}

\begin{frame}
\frametitle{Bits in Hydrological Simulation Context}
 $$ Hydrological \ Simulation \left\{
\begin{aligned}
 &observation \left\{\begin{aligned}
&{\color{red}{ Input \ Measurements  \ X_i}} \\
&{\color{red}{ Output \ Measurements \ X_o}} \\
\end{aligned}\right.\\
\\
 &Model \ \ \left\{\begin{aligned}
&{\color{red}{Output\ Simulation \ X_s}}\\
&{\color{blue}{State\ Variable \ Simulation \ S }} \\
&Parameters \\
&Model Structure \\
\end{aligned}\right.\\
\end{aligned}
\right.
$$ 
\end{frame}

\begin{frame}
\frametitle{Bits in Hydrological Simulation Context}
\onslide<1->{
\begin{itemize}
\item For a time/frequency/feature-space domain base,
\begin{itemize}
\item $X_i$,$X_o$,$X_s$,$S$ are represented by their coordinates,
\begin{itemize}
\item Entropy / Kolmogorov Complexity of these coordinates represents the complexity of expressing the signals with that base:
\\$H(X_o)$ /  $KC(X_o)$: Bits are required to depict $X_o$.
\item Shannon / Kolmogorov Mutual Information between   coordinates represents the information connection of the signals at that base:
\\$MI(X_i,X_o)$: Bits provided by $X_i$.
\\$MI(X_s,X_o)$: Bits provided by Model.
\end{itemize}
\end{itemize}
\end{itemize}}
\onslide<2->{
\begin{align*}
  &Aleatory  \ Uncertainty=H(X_o)/ KC(X_o)-MI(X_i,X_o)    \onslide<3->{\ \color{red}{Noise}}   \\
  &Epistemic \ Uncertainty=MI(X_i,X_o)-MI(X_s,X_o) \onslide<3->{\ \color{red}{Signal}}
\end{align*}} 
\end{frame}


\begin{frame}
\frametitle{Case Study 1: How water-heat correlation emerges through temporal upscaling}
\center{\tiny{Relation of MI,Scale,Previous-Input-Step}}
\begin{figure}[H]\centering
\includegraphics[width=.2\textwidth]{MI_QP_SHORT.png}
\includegraphics[width=.2\textwidth]{MI_QPEP_SHORT.png}
\includegraphics[width=.2\textwidth]{MI_QPEPQ_SHORT.png}
\end{figure} 

\begin{figure}[H]\centering
\includegraphics[width=.2\textwidth]{MI_QP_LONG.png}
\includegraphics[width=.2\textwidth]{MI_QPEP_LONG.png}
\includegraphics[width=.2\textwidth]{MI_QPEPQ_LONG.png}
\center{\tiny{Signal-to-noise Ratio Across Temporal Scales}}  
\begin{figure}[H]\centering
\includegraphics[width=.8\textwidth]{entropy_aligned.png}  
\end{figure} 
\end{figure} 
\end{frame}


 
\begin{frame}
\frametitle{Case Study 2: To what ratio can hydrological data be compressed}
\begin{figure}[H]\centering
\includegraphics[width=.24\textwidth]{datasize.png}
\end{figure}
\center{Huffman Encoding \raisebox{0.5mm}{------} Lisp Implementation}
\begin{figure}[H]\centering
\includegraphics[width=.26\textwidth]{01048000.png}
\includegraphics[width=.26\textwidth]{02143000.png}
\includegraphics[width=.26\textwidth]{05418500.png}
\includegraphics[width=.26\textwidth]{06810000.png}
\end{figure}  
\end{frame} 

\begin{frame}
\frametitle{Case Study 2: To what ratio can hydrological data be compressed}
\begin{figure}[H]\centering
\includegraphics[width=.78\textwidth]{compress.png}
\end{figure}
\tiny{Weijs S V, Giesen N, Parlange M B. Data compression to define information content of hydrological time series[J]. Hydrology and Earth System Sciences, 2013, 17(8): 3171-3187.} 
\end{frame} 
\begin{frame}
\frametitle{Discussion \& Conclusion}
%In compression, not all patterns found in the data set should be attributed to the rainfall-runoff process.
  Coding is not merely an E.E. trick. It's hard to tell where data science stops and coding starts.
\begin{itemize}
\item Significance Digging
\item Application Expansion
\end{itemize}
\end{frame}

\begin{frame}
\begin{figure}[H]\centering
\includegraphics[width=0.2\textwidth]{goat.jpg}
\end{figure}
\center{https://github.com/morepenn}
\center{END}
\end{frame} 

\end{CJK}
\end{document}
